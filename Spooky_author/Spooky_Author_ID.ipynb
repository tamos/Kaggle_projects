{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple implementation of text as vectors for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "import collections\n",
    "import string\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "work_dir = %pwd # Get the working directory.\n",
    "training_set = pd.read_csv(str(work_dir + \"/\" + \"train.csv\")) # Read in the training data.\n",
    "test_set = pd.read_csv(str(work_dir + \"/\" + \"test.csv\")) # Read in the test data.\n",
    "#training_set = training_set[0:100]\n",
    "training_set.columns = ['id', 'text', 'written_by']\n",
    "print('Data loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text cleaned and preprocessed.\n",
      "Counts dataframe created\n",
      "Text cleaned and preprocessed.\n",
      "Counts dataframe created\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text, keep_words = []):\n",
    "    # Build a list of lists with the split, lower text.\n",
    "    text = [i.lower().split() for i in text['text']]\n",
    "    \n",
    "    # Get rid of words if using a vocabulary.\n",
    "    if len(keep_words) > 0:\n",
    "        for i in text:\n",
    "            for j in i:\n",
    "                if j not in keep_words:\n",
    "                    i.remove(j)\n",
    "    new_lol = []\n",
    "    # Make a list of lists with punctuation removed.\n",
    "    for i in text: \n",
    "        sub_lol = []\n",
    "        for j in i:\n",
    "            sub_lol.append(j.strip(string.punctuation))\n",
    "        new_lol.append(sub_lol)\n",
    "    text_lol = new_lol\n",
    "\n",
    "    # Find all words, their counts, and unique words. \n",
    "    all_words = [j for i in text_lol for j in i]\n",
    "    word_counts = collections.Counter(all_words)\n",
    "    unique_words = set([j for i in text_lol for j in i])\n",
    "    \n",
    "    print('Text cleaned and preprocessed.')\n",
    "    \n",
    "    # Get some basic dimensions and create an empty array.\n",
    "    n_cases = len(text_lol)\n",
    "    n_words = len(unique_words)\n",
    "    zero_array = np.zeros((n_cases, n_words))\n",
    "    count_frame = pd.DataFrame(zero_array, columns = unique_words)\n",
    "    #print('count frame is', count_frame.iloc[1:10,:])\n",
    "\n",
    "    #  Get counts for all cases and place in the dataframe.\n",
    "    for i in range(n_cases):\n",
    "        count_words = collections.Counter(text_lol[i])\n",
    "        for j in count_words.keys():\n",
    "            count_frame.iloc[i][j] += 1\n",
    "    print('Counts dataframe created')\n",
    "    \n",
    "    return count_frame, unique_words\n",
    "\n",
    "count_frame, vocab = clean_text(training_set)\n",
    "test_frame, test_vocab = clean_text(test_set, vocab)\n",
    "\n",
    "test_frame, train_frame = test_frame.align(count_frame, axis = 1, join = 'inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reindexed, count frame created\n"
     ]
    }
   ],
   "source": [
    "# Reindex by author and count\n",
    "train_frame.index = training_set['written_by']\n",
    "by_author_train = train_frame.groupby('written_by').aggregate(sum) \n",
    "print('Reindexed, count frame created')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_angle_calculator(v1, v2, radians = True):\n",
    "    '''Calculates angle between two vectors.\n",
    "    In: 2 vectors (v1, v2); radians or degrees\n",
    "    Out: radian or degree values\n",
    "    '''\n",
    "    # Calculate angle between two vectors\n",
    "    v1_dot_v2 = sum([v1[i] * v2[i] for i in range(len(v1))])\n",
    "    #print('Dot product is:', v1_dot_v2)\n",
    "    mag_v1 = math.sqrt(sum([i**2 for i in v1]))\n",
    "    #print('Magnitude of first vector is:', mag_v1)\n",
    "    mag_v2 = math.sqrt(sum([i**2 for i in v2]))\n",
    "    #print('Magnitude of second vector is:', mag_v1)\n",
    "    angle_pre_acos = v1_dot_v2 / (mag_v1 * mag_v2)\n",
    "    #print('this is value going into arcos', angle_pre_acos)\n",
    "    if angle_pre_acos > 1:\n",
    "        angle_pre_acos = 1.0\n",
    "    if angle_pre_acos < -1:\n",
    "        angle_pre_acos = -1.0\n",
    "    theta_val = math.acos(angle_pre_acos)\n",
    "    #print('Theta in radians is:', theta_val)\n",
    "    #print('Theta in degrees is:', math.degrees(theta_val))\n",
    "    if radians == True:\n",
    "        return theta_val\n",
    "    else:\n",
    "        return math.degrees(theta_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_match(count_frame, target):\n",
    "    print('Finding best match...')\n",
    "    match_dict = {}\n",
    "    match_list = []\n",
    "    counter = 0\n",
    "    for i in count_frame.iterrows():\n",
    "        print('At count_frame case:', counter)\n",
    "        angle_btwn = vector_angle_calculator(i[1], target)\n",
    "        #print('Angle calculated', angle_btwn)\n",
    "        match_list.append(angle_btwn)\n",
    "        match_dict[angle_btwn] = i[0]\n",
    "        counter += 1\n",
    "    print('Best match found.')\n",
    "    return match_dict[min(match_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_author(train_values, test_values):\n",
    "    count = 0\n",
    "    predictions = []\n",
    "    for i in test_values.iterrows():\n",
    "        print('\\n At case:', count, '\\n')\n",
    "        match = find_best_match(train_values, i)\n",
    "        predictions.append(match)\n",
    "        print('Match is:', match)\n",
    "        #print('Real value is:', test_frame.index[i])\n",
    "        count += 1\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reindex by author and count\n",
    "count_frame.index = training_set['written_by']\n",
    "by_author = count_frame.groupby('written_by').aggregate(sum) \n",
    "print('Reindexed, count frame created')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_angle_calculator(v1, v2, radians = True):\n",
    "    # Calculate angle between two vectors\n",
    "    v1_dot_v2 = sum([v1[i] * v2[i] for i in range(len(v1))])\n",
    "    #print('Dot product is:', v1_dot_v2)\n",
    "    mag_v1 = math.sqrt(sum([i**2 for i in v1]))\n",
    "    #print('Magnitude of first vector is:', mag_v1)\n",
    "    mag_v2 = math.sqrt(sum([i**2 for i in v2]))\n",
    "    #print('Magnitude of second vector is:', mag_v1)\n",
    "    angle_pre_acos = v1_dot_v2 / (mag_v1 * mag_v2)\n",
    "    #print('this is value going into arcos', angle_pre_acos)\n",
    "    if angle_pre_acos > 1:\n",
    "        angle_pre_acos = 1.0\n",
    "    if angle_pre_acos < -1:\n",
    "        angle_pre_acos = -1.0\n",
    "    theta_val = math.acos(angle_pre_acos)\n",
    "    #print('Theta in radians is:', theta_val)\n",
    "    #print('Theta in degrees is:', math.degrees(theta_val))\n",
    "    if radians == True:\n",
    "        return theta_val\n",
    "    else:\n",
    "        return math.degrees(theta_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_match(count_frame, target):\n",
    "    print('Finding best match...')\n",
    "    match_dict = {}\n",
    "    match_list = []\n",
    "    counter = 0\n",
    "    for i in count_frame.iterrows():\n",
    "        print('At count_frame case:', counter)\n",
    "        angle_btwn = vector_angle_calculator(i[1], target)\n",
    "        #print('Angle calculated', angle_btwn)\n",
    "        match_list.append(angle_btwn)\n",
    "        match_dict[angle_btwn] = i[0]\n",
    "        counter += 1\n",
    "    print('Best match found.')\n",
    "    return match_dict[min(match_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_author(test_values):\n",
    "    test_frame = pd.read_csv(str(work_dir + \"/\" + \"test.csv\")) # Read in the test data.\n",
    "    # Get rid of words not in training data.\n",
    "    \n",
    "    count = 0\n",
    "    predictions = []\n",
    "    counted_predictions = collections.Counter()\n",
    "    for i in range(np.shape(test_frame)[0]):\n",
    "        print('\\n At case:', count, '\\n')\n",
    "        match = find_best_match(count_frame, count_frame.iloc[i,:])\n",
    "        predictions.append(match)\n",
    "        print('Match is:', match)\n",
    "        print('Real value is:', test_frame.index[i])\n",
    "        count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_frame = pd.read_csv(str(work_dir + \"/\" + \"test.csv\")) # Read in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasher = FeatureHasher(input_type='string')\n",
    "#hashed_text = hasher.transform(training_set['text'])\n",
    "hashed_text_array = hashed_text.toarray()\n",
    "hashed_text_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
